version: '3.8'

services:
  dartsgpt:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: dartsgpt
    environment:
      # OpenAI Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      
      # Vector Store Configuration
      - VECTOR_STORE_TYPE=${VECTOR_STORE_TYPE:-chroma}
      - VECTOR_STORE_PATH=/app/embeddings
      
      # LangChain Configuration (optional)
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-true}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT:-dartsgpt}
      
      # DARTS Configuration
      - DARTS_MODELS_PATH=/app/knowledge/darts-code/open-darts-main/models
      - DARTS_DEVELOPMENT_PATH=/app/knowledge/darts-code/darts-models-development
      - DARTS_TEMPLATES_PATH=/app/knowledge/templates
      
      # Application Configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - DEBUG_MODE=${DEBUG_MODE:-false}
      
    ports:
      - "8502:8502"  # Streamlit UI
    
    volumes:
      # Persist embeddings
      - ./embeddings:/app/embeddings
      # Persist generated models
      - ./output:/app/output
      # Persist logs
      - ./logs:/app/logs
      # Mount knowledge base (optional, for development)
      # - ./knowledge:/app/knowledge:ro
    
    restart: unless-stopped
    
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
  
  # Optional: CLI service for running commands
  dartsgpt-cli:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: dartsgpt-cli
    environment:
      # Same environment variables as above
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - VECTOR_STORE_TYPE=${VECTOR_STORE_TYPE:-chroma}
      - VECTOR_STORE_PATH=/app/embeddings
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-true}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT:-dartsgpt}
      - DARTS_MODELS_PATH=/app/knowledge/darts-code/open-darts-main/models
      - DARTS_DEVELOPMENT_PATH=/app/knowledge/darts-code/darts-models-development
      - DARTS_TEMPLATES_PATH=/app/knowledge/templates
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - DEBUG_MODE=${DEBUG_MODE:-false}
    
    volumes:
      - ./embeddings:/app/embeddings
      - ./output:/app/output
      - ./logs:/app/logs
    
    # Override command for CLI
    command: ["uv", "run", "python", "main.py", "--help"]
    
    # Don't restart automatically (for one-off commands)
    restart: "no"
    
    profiles:
      - cli  # Only start when explicitly requested

# Optional: Add a volume for persistent storage
volumes:
  embeddings:
  output:
  logs: